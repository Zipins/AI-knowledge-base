# app.py
import streamlit as st
from rag_qa import (
    answer_question,
    get_loaded_docs_summary,
    force_rebuild_vectorstore,
)

st.set_page_config(page_title="å†…éƒ¨çŸ¥è¯†åº“åŠ©æ‰‹", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– å…¬å¸å†…éƒ¨ AI çŸ¥è¯†åº“åŠ©æ‰‹")
st.write("AI å°† **ä¸¥æ ¼æ ¹æ®ä½ ä¸Šä¼ åˆ° Google Drive çš„çŸ¥è¯†åº“æ–‡æ¡£** æ¥å›ç­”é—®é¢˜ã€‚")

# ä¿å­˜å¯¹è¯å†å²
if "history" not in st.session_state:
    st.session_state["history"] = []

# é—®é¢˜è¾“å…¥
question = st.text_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼š", "")

col1, col2 = st.columns([3, 1])
with col1:
    submit = st.button("æäº¤é—®é¢˜", use_container_width=True)
with col2:
    rebuild = st.button("ğŸ”„ å¼ºåˆ¶é‡å»ºçŸ¥è¯†åº“å‘é‡åº“", use_container_width=True)

# æ‰‹åŠ¨é‡å»ºæŒ‰é’®
if rebuild:
    with st.spinner("æ­£åœ¨ä» Google Drive é‡æ–°åŒæ­¥å¹¶é‡å»ºå‘é‡åº“..."):
        meta = force_rebuild_vectorstore()
    st.success("å·²é‡å»ºçŸ¥è¯†åº“å‘é‡åº“ âœ…")
    st.json(meta)

# æäº¤é—®é¢˜
if submit and question.strip():
    with st.spinner("AI æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“å¹¶ç”Ÿæˆå›ç­”..."):
        answer, docs, debug_info = answer_question(question)
        st.session_state["history"].append(
            {
                "question": question,
                "answer": answer,
                "docs": docs,
                "debug_info": debug_info,
            }
        )

# ========== å¯¹è¯è®°å½• ==========
st.subheader("ğŸ’¬ å¯¹è¯è®°å½•")

for qa in reversed(st.session_state["history"]):
    st.markdown(f"**ğŸ§‘â€ğŸ’¼ ä½ é—®ï¼š** {qa['question']}")
    st.markdown(f"**ğŸ¤– AI å›ç­”ï¼š**\n\n{qa['answer']}")

    # ç­”æ¡ˆå’Œå¼•ç”¨ç‰‡æ®µä¹‹é—´ç©ºä¸€è¡Œ
    st.markdown("")

    # å±•å¼€æŸ¥çœ‹å‘½ä¸­æ–‡æ¡£ä¿¡æ¯ + åŸæ–‡ç‰‡æ®µ
    with st.expander("ğŸ“„ æŸ¥çœ‹æœ¬æ¬¡æ£€ç´¢å‘½ä¸­çš„çŸ¥è¯†åº“åŸæ–‡ç‰‡æ®µ"):
        debug_info = qa.get("debug_info", {})
        retrieved_sources = debug_info.get("retrieved_sources", [])

        if retrieved_sources:
            st.markdown("**æœ¬æ¬¡å‘½ä¸­æ–‡æ¡£åˆ—è¡¨ï¼š**")
            for src in retrieved_sources:
                st.markdown(
                    f"- **Top {src['rank']}**  "
                    f"æ¥æº: `{src['source']}`  "
                    f"æ ‡é¢˜: {src.get('title','') or '(æ— æ ‡é¢˜)' }  "
                    f"ä¿®æ”¹æ—¶é—´: {src.get('modifiedTime','')}"
                )
        else:
            st.write("ï¼ˆæœ¬æ¬¡æ²¡æœ‰è°ƒè¯•ä¿¡æ¯ï¼‰")

        st.markdown("---")
        st.markdown("**å…·ä½“ç‰‡æ®µå†…å®¹ï¼š**")

        if qa["docs"]:
            for i, d in enumerate(qa["docs"], start=1):
                source = d.metadata.get("source") or "æœªå‘½åæ–‡ä»¶"
                st.markdown(f"**ç‰‡æ®µ {i} - æ¥æºæ–‡ä»¶ï¼š{source}**")
                st.write(d.page_content)
                st.markdown("---")
        else:
            st.write("æœ¬æ¬¡å›ç­”æœªå¼•ç”¨å…·ä½“æ–‡æ¡£ç‰‡æ®µã€‚")

    st.markdown("---")

# ========== çŸ¥è¯†åº“ç®¡ç† / è°ƒè¯•åŒºåŸŸ ==========
st.subheader("ğŸ›  çŸ¥è¯†åº“ç®¡ç† / è°ƒè¯•")

with st.expander("ğŸ“š å½“å‰å·²åŠ è½½çš„çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨"):
    docs_summary = get_loaded_docs_summary()
    st.write(f"å½“å‰å†…å­˜ä¸­å·²åŠ è½½æ–‡æ¡£æ•°é‡ï¼š**{len(docs_summary)}**")

    if not docs_summary:
        st.caption("æš‚æ—¶è¿˜æ²¡æœ‰åŠ è½½æ–‡æ¡£ï¼ˆç­‰ç¬¬ä¸€æ¬¡æ£€ç´¢æˆ–ç‚¹å‡»é‡å»ºåä¼šå‡ºç°ï¼‰ã€‚")
    else:
        for i, d in enumerate(docs_summary, start=1):
            st.markdown(
                f"{i}. **{d['title'] or '(æ— æ ‡é¢˜)'}**  \n"
                f"`source`: `{d['source']}`  \n"
                f"`ä¿®æ”¹æ—¶é—´`: {d['modifiedTime']}  \n"
                f"`å­—ç¬¦æ•°`: {d['chars']}"
            )
            st.markdown("---")
